{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\n\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom pytorch_lightning import LightningModule","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-07T19:17:46.663851Z","iopub.execute_input":"2021-08-07T19:17:46.664277Z","iopub.status.idle":"2021-08-07T19:17:47.916333Z","shell.execute_reply.started":"2021-08-07T19:17:46.664219Z","shell.execute_reply":"2021-08-07T19:17:47.915121Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class VolatilityClassifier(LightningModule):\n\n    def __init__(self, input_width=600):\n\n        super(VolatilityClassifier, self).__init__()\n\n        in_channels = 10\n        hidden_size = input_width\n\n        self.batchnorm = nn.BatchNorm1d(in_channels)\n\n        self.conv1 = nn.Conv1d(in_channels, in_channels*8, kernel_size=3, padding=1, bias=True)\n        self.conv2 = nn.Conv1d(in_channels*8, in_channels*8, kernel_size=3, padding=1, bias=True)\n        self.conv3 = nn.Conv1d(in_channels*8, in_channels*4, kernel_size=3, padding=1, bias=True)\n\n        self.dense = nn.Linear(in_channels*4*600, 1)\n\n        self.linear = nn.Linear(2, 1)\n\n        self.loss = nn.MSELoss()\n        \n    def forward(self, series, stats):\n\n        x = self.batchnorm(series)\n\n        x = self.conv1(x)\n        x = F.leaky_relu(x)\n\n        x = self.conv2(x)\n        x = F.leaky_relu(x)\n\n        x = self.conv3(x)\n        x = F.leaky_relu(x)\n\n        x = torch.flatten(x, start_dim=1, end_dim=2)\n        x = self.dense(x)\n\n        x = torch.hstack((x,stats))\n\n        return self.linear(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:47.922998Z","iopub.execute_input":"2021-08-07T19:17:47.923325Z","iopub.status.idle":"2021-08-07T19:17:47.935613Z","shell.execute_reply.started":"2021-08-07T19:17:47.923284Z","shell.execute_reply":"2021-08-07T19:17:47.934136Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_tensors(file_path):\n\n    df = pd.read_parquet(file_path, engine='pyarrow')\n    stock_id = int(file_path.split('/')[-1].split('=')[-1])\n\n    for time_id in np.unique(df.time_id):\n\n        df_time = df[df.time_id == time_id].reset_index(drop=True)\n        changes_len = len(df_time)\n\n        df_time = df_time.reindex(list(range(600))).reset_index(drop=True)\n\n        missing = set(range(600)) - set(df_time.seconds_in_bucket)\n        df_time.loc[changes_len:,'seconds_in_bucket'] = list(missing)\n\n        df_time = df_time.sort_values(by='seconds_in_bucket').reset_index(drop=True)\n        df_time.loc[:,'time_id'] = time_id\n        df_time['stock_id'] = stock_id\n\n        df_time.ffill(axis = 0, inplace=True)\n\n        yield df_time.T.to_numpy(dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:47.937235Z","iopub.execute_input":"2021-08-07T19:17:47.937547Z","iopub.status.idle":"2021-08-07T19:17:47.955122Z","shell.execute_reply.started":"2021-08-07T19:17:47.937518Z","shell.execute_reply":"2021-08-07T19:17:47.954058Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = VolatilityClassifier.load_from_checkpoint('../input/optiver-best/optiver_best.ckpt')\nmodel.cpu()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:47.956189Z","iopub.execute_input":"2021-08-07T19:17:47.956477Z","iopub.status.idle":"2021-08-07T19:17:47.985812Z","shell.execute_reply.started":"2021-08-07T19:17:47.956450Z","shell.execute_reply":"2021-08-07T19:17:47.984972Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"VolatilityClassifier(\n  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv1): Conv1d(10, 80, kernel_size=(3,), stride=(1,), padding=(1,))\n  (conv2): Conv1d(80, 80, kernel_size=(3,), stride=(1,), padding=(1,))\n  (conv3): Conv1d(80, 40, kernel_size=(3,), stride=(1,), padding=(1,))\n  (dense): Linear(in_features=24000, out_features=1, bias=True)\n  (linear): Linear(in_features=2, out_features=1, bias=True)\n  (loss): MSELoss()\n)"},"metadata":{}}]},{"cell_type":"code","source":"book_test_files = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:47.986960Z","iopub.execute_input":"2021-08-07T19:17:47.987249Z","iopub.status.idle":"2021-08-07T19:17:47.992256Z","shell.execute_reply.started":"2021-08-07T19:17:47.987221Z","shell.execute_reply":"2021-08-07T19:17:47.991591Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tensors = []\n\nfor f in book_test_files:\n    print(f)\n    tensors.extend(list(get_tensors(f)))\n    \ntensors = np.stack(tensors, axis=0)\nnp.nan_to_num(tensors, copy=False)\n\nstockids = tensors[:,-1,0]\ntimeids  = tensors[:,0,0]\n\ndf = pd.DataFrame(data=np.hstack((stockids.reshape(-1,1),timeids.reshape(-1,1))), columns=[\"row_id\", \"target\"])\n\ndf['row_id'] = df['row_id'].astype('int').astype('str') + '-' + df['target'].astype('int').astype('str')\ndf['target'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:47.993379Z","iopub.execute_input":"2021-08-07T19:17:47.993697Z","iopub.status.idle":"2021-08-07T19:17:48.050720Z","shell.execute_reply.started":"2021-08-07T19:17:47.993667Z","shell.execute_reply":"2021-08-07T19:17:48.049780Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/stock_id=0\n","output_type":"stream"}]},{"cell_type":"code","source":"tensors[:,0] = (tensors[:,2]*tensors[:,7] + tensors[:,3]* tensors[:,6]) / (tensors[:,6] + tensors[:,7]) \ntensors[:,1] = np.diff(np.log(tensors[:,0]), prepend=0)  #TODO\n\nstats = np.apply_along_axis(lambda x : np.sqrt(np.sum(x**2)), 1, tensors[:,1]).reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:48.051967Z","iopub.execute_input":"2021-08-07T19:17:48.052266Z","iopub.status.idle":"2021-08-07T19:17:48.058769Z","shell.execute_reply.started":"2021-08-07T19:17:48.052237Z","shell.execute_reply":"2021-08-07T19:17:48.057803Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df['target'] = model(torch.Tensor(tensors[:,:-1]), torch.Tensor(stats)).detach().numpy().squeeze()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:48.061779Z","iopub.execute_input":"2021-08-07T19:17:48.062302Z","iopub.status.idle":"2021-08-07T19:17:48.082470Z","shell.execute_reply.started":"2021-08-07T19:17:48.062255Z","shell.execute_reply":"2021-08-07T19:17:48.081522Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T19:17:48.083819Z","iopub.execute_input":"2021-08-07T19:17:48.084141Z","iopub.status.idle":"2021-08-07T19:17:48.093221Z","shell.execute_reply.started":"2021-08-07T19:17:48.084111Z","shell.execute_reply":"2021-08-07T19:17:48.092120Z"},"trusted":true},"execution_count":9,"outputs":[]}]}